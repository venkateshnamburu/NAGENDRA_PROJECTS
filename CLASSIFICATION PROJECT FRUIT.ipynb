{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bd3126a-a633-4104-8bfc-3bee32765425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ddae28-b2e3-422a-8092-fe497233f0e7",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d289057-150b-478c-a27e-fc2d1c9ca6db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit_label</th>\n",
       "      <th>fruit_name</th>\n",
       "      <th>fruit_subtype</th>\n",
       "      <th>mass</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>color_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>192</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>180</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>176</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>86</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fruit_label fruit_name fruit_subtype  mass  width  height  color_score\n",
       "0            1      apple  granny_smith   192    8.4     7.3         0.55\n",
       "1            1      apple  granny_smith   180    8.0     6.8         0.59\n",
       "2            1      apple  granny_smith   176    7.4     7.2         0.60\n",
       "3            2   mandarin      mandarin    86    6.2     4.7         0.80\n",
       "4            2   mandarin      mandarin    84    6.0     4.6         0.79"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('D:\\\\5.1_Machine_Learning_Code\\\\Classification\\\\fruit_data_with_colors.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc39a509-bf65-4cf6-8d91-ee5b09347c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input and Output Variables\n",
    "feature_names = ['mass', 'width', 'height', 'color_score']\n",
    "X = df[feature_names]\n",
    "y = df['fruit_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a93466be-be88-4454-8d45-660e61a36546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 7)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a75ac41-1271-4437-89d7-51b0514a84d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 4) (18, 4) (41,) (18,)\n"
     ]
    }
   ],
   "source": [
    "#Scaling X and y\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "#Splitting dataset into Train Test 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1, stratify = y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75419de0-d7f8-484b-ac16-cee2d42456cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govindarajulu\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([3, 1, 1, 3, 4, 3, 4, 1, 3, 3, 4, 3, 3, 4, 3, 1, 2, 4], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Predicting\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e38c8b6e-a18c-4550-94e8-1d9adb3f67f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.8292682926829268\n",
      "Accuracy of Logistic Regression classifier on test set: 0.8888888888888888\n",
      "test_cal\n",
      "    fruit_label  predicted\n",
      "0             3          3\n",
      "1             1          1\n",
      "2             1          1\n",
      "3             3          3\n",
      "4             4          4\n",
      "5             3          3\n",
      "6             4          4\n",
      "7             1          1\n",
      "8             3          3\n",
      "9             3          3\n",
      "10            4          4\n",
      "11            3          3\n",
      "12            1          3\n",
      "13            4          4\n",
      "14            1          3\n",
      "15            1          1\n",
      "16            2          2\n",
      "17            4          4\n",
      "[[4 0 2 0]\n",
      " [0 1 0 0]\n",
      " [0 0 6 0]\n",
      " [0 0 0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.67      0.80         6\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       0.75      1.00      0.86         6\n",
      "           4       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.89        18\n",
      "   macro avg       0.94      0.92      0.91        18\n",
      "weighted avg       0.92      0.89      0.89        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of Prediction\n",
    "print('Accuracy of Logistic Regression classifier on training set: {}'.format(model.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic Regression classifier on test set: {}'.format(model.score(X_test, y_test)))\n",
    "\n",
    "# Combine y_test and y_pred into a DataFrame\n",
    "test_cal = pd.concat([pd.DataFrame(y_test).reset_index(drop=True),pd.DataFrame(y_pred).reset_index(drop=True)],axis=1)\n",
    "print('test_cal')\n",
    "\n",
    "# Rename the predicted column\n",
    "test_cal.rename(columns={0: 'predicted'}, inplace=True)\n",
    "print(test_cal)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_df = confusion_matrix(test_cal['fruit_label'], test_cal['predicted'])\n",
    "print(conf_df)\n",
    "\n",
    "# Classification Report\n",
    "metric_report = classification_report(test_cal['fruit_label'], test_cal['predicted'])\n",
    "print(metric_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d7624f-92a8-422f-904a-b472077838f8",
   "metadata": {},
   "source": [
    "## GRIDSEARCH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "301aadec-c93a-4295-ba90-6719e499c866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govindarajulu\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "Best hyperparameters: {'C': 10, 'max_iter': 100, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Accuracy of Logistic Regression classifier on training set: 0.8292682926829268\n",
      "Accuracy of Logistic Regression classifier on test set: 0.8333333333333334\n",
      "[[3 0 3 0]\n",
      " [0 1 0 0]\n",
      " [0 0 6 0]\n",
      " [0 0 0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.50      0.67         6\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       0.67      1.00      0.80         6\n",
      "           4       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.83        18\n",
      "   macro avg       0.92      0.88      0.87        18\n",
      "weighted avg       0.89      0.83      0.82        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govindarajulu\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'solver': ['liblinear', 'lbfgs', 'newton-cg'],  # Solvers to try\n",
    "    'penalty': ['l2'],  # Regularization type (l1 and elasticnet are less commonly used for logistic regression)\n",
    "    'max_iter': [100, 200, 500]  # Number of iterations\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=LogisticRegression(), param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predicting with the best model\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Accuracy of Prediction with best model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {}'.format(best_model.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic Regression classifier on test set: {}'.format(best_model.score(X_test, y_test)))\n",
    "\n",
    "# Combine y_test and y_pred into a DataFrame\n",
    "test_cal_best = pd.concat([pd.DataFrame(y_test).reset_index(drop=True), pd.DataFrame(y_pred_best).reset_index(drop=True)], axis=1)\n",
    "test_cal_best.rename(columns={0: 'predicted'}, inplace=True)\n",
    "\n",
    "# Confusion Matrix with the best model\n",
    "conf_df_best = confusion_matrix(test_cal_best['fruit_label'], test_cal_best['predicted'])\n",
    "print(conf_df_best)\n",
    "\n",
    "# Classification Report with the best model\n",
    "metric_report_best = classification_report(test_cal_best['fruit_label'], test_cal_best['predicted'])\n",
    "print(metric_report_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355d382f-bda5-4248-800e-0a6ff74196e5",
   "metadata": {},
   "source": [
    "## RANDOMIZED SEARCH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e64e08c-9044-44d8-a77a-2b9dc821a77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govindarajulu\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:776: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best hyperparameters (Randomized): {'C': 18.053840579652107, 'max_iter': 500, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Accuracy of Logistic Regression classifier on training set: 0.8292682926829268\n",
      "Accuracy of Logistic Regression classifier on test set: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govindarajulu\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Hyperparameter distributions\n",
    "param_dist = {\n",
    "    'C': uniform(0.001, 100),  # Uniform distribution for C\n",
    "    'solver': ['liblinear', 'lbfgs', 'newton-cg'],\n",
    "    'penalty': ['l2'],\n",
    "    'max_iter': [100, 200, 500]\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=LogisticRegression(), param_distributions=param_dist, n_iter=100, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit random search\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters\n",
    "print(\"Best hyperparameters (Randomized):\", random_search.best_params_)\n",
    "\n",
    "# Best model\n",
    "best_model_random = random_search.best_estimator_\n",
    "\n",
    "# Predicting with the best model\n",
    "y_pred_random = best_model_random.predict(X_test)\n",
    "\n",
    "# Accuracy of Prediction with best model\n",
    "print('Accuracy of Logistic Regression classifier on training set: {}'.format(best_model_random.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic Regression classifier on test set: {}'.format(best_model_random.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4569ab5-bf99-4e27-b65a-fedb03d59ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed4c889-9f3d-4ac3-b72e-4794fdf08346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a5a19f5-8835-41b9-bd84-75594ebfaabc",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ef6c152-b0fd-4a0a-95a5-8795c8278d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fruit_label</th>\n",
       "      <th>fruit_name</th>\n",
       "      <th>fruit_subtype</th>\n",
       "      <th>mass</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>color_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>192</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>180</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>apple</td>\n",
       "      <td>granny_smith</td>\n",
       "      <td>176</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>86</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>mandarin</td>\n",
       "      <td>84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fruit_label fruit_name fruit_subtype  mass  width  height  color_score\n",
       "0            1      apple  granny_smith   192    8.4     7.3         0.55\n",
       "1            1      apple  granny_smith   180    8.0     6.8         0.59\n",
       "2            1      apple  granny_smith   176    7.4     7.2         0.60\n",
       "3            2   mandarin      mandarin    86    6.2     4.7         0.80\n",
       "4            2   mandarin      mandarin    84    6.0     4.6         0.79"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('D:\\\\5.1_Machine_Learning_Code\\\\Classification\\\\fruit_data_with_colors.txt')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e09a41ca-1bc4-4dcc-b082-da85a03fe177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 4) (18, 4) (41,) (18,)\n"
     ]
    }
   ],
   "source": [
    "#Input and Output Variables\n",
    "feature_names = ['mass', 'width', 'height', 'color_score']\n",
    "X = df[feature_names]\n",
    "y = df['fruit_label']\n",
    "\n",
    "#Scaling X and y\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "#Splitting dataset into Train Test 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1, stratify = y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e4ab7c7-9db3-40a5-9836-4d02e3ef78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive Bayes Model\n",
    "nb =  GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "#Predicting\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b851b06-b212-4787-82ce-b111e3280f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 1, 3, 4, 3, 4, 1, 3, 3, 4, 4, 1, 4, 1, 1, 2, 4], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5804cb2b-2346-4e4e-ae74-87d145846730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression classifier on training set: 0.8536585365853658\n",
      "Accuracy of Logistic Regression classifier on test set: 0.9444444444444444\n",
      "test_cal\n",
      "    fruit_label  predicted\n",
      "0             3          3\n",
      "1             1          1\n",
      "2             1          1\n",
      "3             3          3\n",
      "4             4          4\n",
      "5             3          3\n",
      "6             4          4\n",
      "7             1          1\n",
      "8             3          3\n",
      "9             3          3\n",
      "10            4          4\n",
      "11            3          3\n",
      "12            1          3\n",
      "13            4          4\n",
      "14            1          3\n",
      "15            1          1\n",
      "16            2          2\n",
      "17            4          4\n",
      "[[6 0 0 0]\n",
      " [0 1 0 0]\n",
      " [0 0 5 1]\n",
      " [0 0 0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      0.83      0.91         6\n",
      "           4       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.94        18\n",
      "   macro avg       0.96      0.96      0.95        18\n",
      "weighted avg       0.95      0.94      0.94        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of Prediction\n",
    "print('Accuracy of Logistic Regression classifier on training set: {}'.format(nb.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic Regression classifier on test set: {}'.format(nb.score(X_test, y_test)))\n",
    "\n",
    "# Combine y_test and y_pred into a DataFrame\n",
    "test_calc = pd.concat([pd.DataFrame(y_test).reset_index(drop=True),pd.DataFrame(y_pred).reset_index(drop=True)],axis=1)\n",
    "print('test_cal')\n",
    "\n",
    "# Rename the predicted column\n",
    "test_calc.rename(columns={0: 'predicted'}, inplace=True)\n",
    "print(test_cal)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_df = confusion_matrix(test_calc['fruit_label'], test_calc['predicted'])\n",
    "print(conf_df)\n",
    "\n",
    "# Classification Report\n",
    "metric_report = classification_report(test_calc['fruit_label'], test_calc['predicted'])\n",
    "print(metric_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102935a5-5143-4165-a332-9cb49be1e8fb",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9190f729-8a29-4afd-9359-75903ece24df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 4) (18, 4) (41,) (18,)\n",
      "Accuracy of Logistic Regression classifier on training set: 0.3170731707317073\n",
      "Accuracy of Logistic Regression classifier on test set: 0.3333333333333333\n",
      "[[0 0 6 0]\n",
      " [0 0 1 0]\n",
      " [0 0 6 0]\n",
      " [0 0 5 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.33      1.00      0.50         6\n",
      "           4       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.33        18\n",
      "   macro avg       0.08      0.25      0.12        18\n",
      "weighted avg       0.11      0.33      0.17        18\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\govindarajulu\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\govindarajulu\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\govindarajulu\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_table('D:\\\\5.1_Machine_Learning_Code\\\\Classification\\\\fruit_data_with_colors.txt')\n",
    "df.head()\n",
    "\n",
    "#Input and Output Variables\n",
    "feature_names = ['mass', 'width', 'height', 'color_score']\n",
    "X = df[feature_names]\n",
    "y = df['fruit_label']\n",
    "\n",
    "#Scaling X and y\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "#Splitting dataset into Train Test 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1, stratify = y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "#Stochastic Gradient Descent Model\n",
    "sgd = SGDClassifier(shuffle=True,random_state=101)\n",
    "sgd.fit(X_train, y_train)\n",
    "\n",
    "#Predicting\n",
    "y_pred = sgd.predict(X_test)\n",
    "\n",
    "#Accuracy of Prediction\n",
    "print('Accuracy of Logistic Regression classifier on training set: {}'.format(sgd.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic Regression classifier on test set: {}'.format(sgd.score(X_test, y_test)))\n",
    "\n",
    "# Rename the predicted column\n",
    "test_calc = pd.concat([pd.DataFrame(y_test).reset_index(drop=True),pd.DataFrame(y_pred).reset_index(drop=True)],axis=1)\n",
    "test_calc.rename(columns={0: 'predicted'}, inplace=True)\n",
    "\n",
    "conf_df = confusion_matrix(test_calc['fruit_label'],test_calc['predicted'])\n",
    "print (conf_df)\n",
    "\n",
    "metric_report = classification_report(test_calc['fruit_label'], test_calc['predicted'])\n",
    "print(metric_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71bfdc5-ab82-4b8b-b062-6251eaebe08a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb99d68d-209c-4e5e-98da-d60bb147d2a3",
   "metadata": {},
   "source": [
    "## GRID SEARCH CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82eb3104-1178-4cc6-945b-355467974284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 405 candidates, totalling 2025 fits\n",
      "Best hyperparameters found: {'alpha': 0.01, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "Accuracy of SGD classifier on training set: 0.3170731707317073\n",
      "Accuracy of SGD classifier on test set: 0.3333333333333333\n",
      "[[0 0 6 0]\n",
      " [0 0 1 0]\n",
      " [0 0 6 0]\n",
      " [0 0 5 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.33      1.00      0.50         6\n",
      "           4       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.33        18\n",
      "   macro avg       0.08      0.25      0.12        18\n",
      "weighted avg       0.11      0.33      0.17        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Hyperparameter grid for SGD\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1],  # Regularization strength\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],  # Types of regularization\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling'],  # Learning rate schedule\n",
    "    'max_iter': [1000, 2000, 3000],  # Number of iterations\n",
    "    'tol': [1e-4, 1e-3, 1e-2]  # Tolerance for stopping criteria\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=SGDClassifier(), param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit grid search to training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(\"Best hyperparameters found:\", grid_search.best_params_)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_sgd = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred_best = best_sgd.predict(X_test)\n",
    "\n",
    "# Accuracy of Prediction with best model\n",
    "print('Accuracy of SGD classifier on training set: {}'.format(best_sgd.score(X_train, y_train)))\n",
    "print('Accuracy of SGD classifier on test set: {}'.format(best_sgd.score(X_test, y_test)))\n",
    "\n",
    "# Combine y_test and y_pred into a DataFrame for evaluation\n",
    "test_calc_best = pd.concat([pd.DataFrame(y_test).reset_index(drop=True), pd.DataFrame(y_pred_best).reset_index(drop=True)], axis=1)\n",
    "test_calc_best.rename(columns={0: 'predicted'}, inplace=True)\n",
    "\n",
    "# Confusion Matrix with the best model\n",
    "conf_df_best = confusion_matrix(test_calc_best['fruit_label'], test_calc_best['predicted'])\n",
    "print(conf_df_best)\n",
    "\n",
    "# Classification Report with the best model\n",
    "metric_report_best = classification_report(test_calc_best['fruit_label'], test_calc_best['predicted'])\n",
    "print(metric_report_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e41bd5-9397-4096-bda9-1ce3b56d99a5",
   "metadata": {},
   "source": [
    "## Randomized SearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdb56210-8e1b-494c-a075-7b7493c9951f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best hyperparameters (Randomized): {'alpha': 0.14935264752060717, 'learning_rate': 'optimal', 'max_iter': 3000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "Accuracy of SGD classifier on training set: 0.3170731707317073\n",
      "Accuracy of SGD classifier on test set: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Hyperparameter distributions\n",
    "param_dist = {\n",
    "    'alpha': uniform(0.0001, 1),  # Uniform distribution for alpha\n",
    "    'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "    'learning_rate': ['constant', 'optimal', 'invscaling'],\n",
    "    'max_iter': [1000, 2000, 3000],\n",
    "    'tol': [1e-4, 1e-3, 1e-2]\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=SGDClassifier(), param_distributions=param_dist, n_iter=100, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit randomized search to training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters from randomized search\n",
    "print(\"Best hyperparameters (Randomized):\", random_search.best_params_)\n",
    "\n",
    "# Best model after hyperparameter tuning\n",
    "best_sgd_random = random_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred_random = best_sgd_random.predict(X_test)\n",
    "\n",
    "# Accuracy of Prediction with best model\n",
    "print('Accuracy of SGD classifier on training set: {}'.format(best_sgd_random.score(X_train, y_train)))\n",
    "print('Accuracy of SGD classifier on test set: {}'.format(best_sgd_random.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482c08da-826f-4320-8cfd-fb0d3d303ca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2c8807c-e5e0-4a4b-af42-c4f89507667e",
   "metadata": {},
   "source": [
    "## K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dd19925f-aa45-4819-bb03-e1845fcc01f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 4) (18, 4) (41,) (18,)\n",
      "Accuracy of Logistic Regression classifier on training set: 0.7804878048780488\n",
      "Accuracy of Logistic Regression classifier on test set: 0.7777777777777778\n",
      "[[4 0 2 0]\n",
      " [0 1 0 0]\n",
      " [0 0 4 2]\n",
      " [0 0 0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.67      0.80         6\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       0.67      0.67      0.67         6\n",
      "           4       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.85      0.83      0.83        18\n",
      "weighted avg       0.81      0.78      0.78        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_table('D:\\\\5.1_Machine_Learning_Code\\\\Classification\\\\fruit_data_with_colors.txt')\n",
    "df.head()\n",
    "\n",
    "#Input and Output Variables\n",
    "feature_names = ['mass', 'width', 'height', 'color_score']\n",
    "X = df[feature_names]\n",
    "y = df['fruit_label']\n",
    "\n",
    "#Scaling X and y\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "#Splitting dataset into Train Test 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1, stratify = y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "#K Nearest Neighbour Model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Predicting\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "#Accuracy of Prediction\n",
    "print('Accuracy of Logistic Regression classifier on training set: {}'.format(knn.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic Regression classifier on test set: {}'.format(knn.score(X_test, y_test)))\n",
    "\n",
    "# Rename the predicted column\n",
    "test_calc = pd.concat([pd.DataFrame(y_test).reset_index(drop=True),pd.DataFrame(y_pred).reset_index(drop=True)],axis=1)\n",
    "test_calc.rename(columns={0: 'predicted'}, inplace=True)\n",
    "\n",
    "conf_df = confusion_matrix(test_calc['fruit_label'],test_calc['predicted'])\n",
    "print (conf_df)\n",
    "\n",
    "metric_report = classification_report(test_calc['fruit_label'], test_calc['predicted'])\n",
    "print(metric_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6029685-5551-4e64-b45e-d66c6384b8d6",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6cc6fb3e-fdac-4f68-8c88-914bc90b5b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 4) (18, 4) (41,) (18,)\n",
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n",
      "Best Hyperparameters: {'leaf_size': 10, 'metric': 'minkowski', 'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n",
      "Accuracy on training set: 0.9512195121951219\n",
      "Accuracy on test set: 0.7777777777777778\n",
      "[[3 0 3 0]\n",
      " [0 1 0 0]\n",
      " [1 0 5 0]\n",
      " [0 0 0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.75      0.50      0.60         6\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       0.62      0.83      0.71         6\n",
      "           4       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           0.78        18\n",
      "   macro avg       0.84      0.83      0.83        18\n",
      "weighted avg       0.79      0.78      0.77        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Input data (assuming the dataframe `df` is already loaded as per your code)\n",
    "feature_names = ['mass', 'width', 'height', 'color_score']\n",
    "X = df[feature_names]\n",
    "y = df['fruit_label']\n",
    "\n",
    "# Scaling X\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting dataset into Train Test 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.30, random_state=1, stratify=y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Define KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define hyperparameter grid to search\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan'],\n",
    "    'leaf_size': [10, 20, 30, 40, 50],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Set up the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Accuracy of Prediction\n",
    "print('Accuracy on training set: {}'.format(grid_search.best_estimator_.score(X_train, y_train)))\n",
    "print('Accuracy on test set: {}'.format(grid_search.best_estimator_.score(X_test, y_test)))\n",
    "\n",
    "# Create a DataFrame for comparison\n",
    "test_calc = pd.concat([pd.DataFrame(y_test).reset_index(drop=True), pd.DataFrame(y_pred).reset_index(drop=True)], axis=1)\n",
    "test_calc.rename(columns={0: 'predicted'}, inplace=True)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_df = confusion_matrix(test_calc['fruit_label'], test_calc['predicted'])\n",
    "print(conf_df)\n",
    "\n",
    "# Classification Report\n",
    "metric_report = classification_report(test_calc['fruit_label'], test_calc['predicted'])\n",
    "print(metric_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b8c430-7e86-4ada-9149-22e66943e685",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68359a5d-903f-4359-b34e-5d0973dc9dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 4) (18, 4) (41,) (18,)\n",
      "Accuracy of Logistic Regression classifier on training set: 0.43902439024390244\n",
      "Accuracy of Logistic Regression classifier on test set: 0.5\n",
      "[[6 0 0 0]\n",
      " [0 1 0 0]\n",
      " [4 0 2 0]\n",
      " [5 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      1.00      0.57         6\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      0.33      0.50         6\n",
      "           4       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.50        18\n",
      "   macro avg       0.60      0.58      0.52        18\n",
      "weighted avg       0.52      0.50      0.41        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "df = pd.read_table('D:\\\\5.1_Machine_Learning_Code\\\\Classification\\\\fruit_data_with_colors.txt')\n",
    "df.head()\n",
    "\n",
    "#Input and Output Variables\n",
    "feature_names = ['mass', 'width', 'height', 'color_score']\n",
    "X = df[feature_names]\n",
    "y = df['fruit_label']\n",
    "\n",
    "#Scaling X and y\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "#Splitting dataset into Train Test 70/30\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1, stratify = y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "#Support Vector Machine Model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "#Predicting\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "#Accuracy of Prediction\n",
    "print('Accuracy of Logistic Regression classifier on training set: {}'.format(svm.score(X_train, y_train)))\n",
    "print('Accuracy of Logistic Regression classifier on test set: {}'.format(svm.score(X_test, y_test)))\n",
    "\n",
    "# Rename the predicted column\n",
    "test_calc = pd.concat([pd.DataFrame(y_test).reset_index(drop=True),pd.DataFrame(y_pred).reset_index(drop=True)],axis=1)\n",
    "test_calc.rename(columns={0: 'predicted'}, inplace=True)\n",
    "\n",
    "conf_df = confusion_matrix(test_calc['fruit_label'],test_calc['predicted'])\n",
    "print (conf_df)\n",
    "\n",
    "metric_report = classification_report(test_calc['fruit_label'], test_calc['predicted'])\n",
    "print(metric_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193079de-0f5b-45b7-a517-58875f84e5e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "328b1992-92dc-4373-ab7c-6c57765b6d0a",
   "metadata": {},
   "source": [
    "## XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01927bc5-ab4c-400b-803c-7b63b0b51b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47, 4) (12, 4) (47,) (12,)\n",
      "Accuracy of XGBoost classifier on training set: 1.0\n",
      "Accuracy of XGBoost classifier on test set: 0.6666666666666666\n",
      "Confusion Matrix:\n",
      "[[2 0 0 2]\n",
      " [0 1 0 0]\n",
      " [0 0 3 1]\n",
      " [0 0 1 2]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       0.75      0.75      0.75         4\n",
      "           3       0.40      0.67      0.50         3\n",
      "\n",
      "    accuracy                           0.67        12\n",
      "   macro avg       0.79      0.73      0.73        12\n",
      "weighted avg       0.77      0.67      0.68        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from xgboost import XGBClassifier  # Importing XGBClassifier from xgboost\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_table('D:\\\\5.1_Machine_Learning_Code\\\\Classification\\\\fruit_data_with_colors.txt')\n",
    "df.head()\n",
    "\n",
    "# Input and Output Variables\n",
    "feature_names = ['mass', 'width', 'height', 'color_score']\n",
    "X = df[feature_names]\n",
    "y = df['fruit_label']\n",
    "\n",
    "# Scaling X\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting dataset into Train and Test (80/20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.20, random_state=1, stratify=y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Encode the labels to start from 0 using LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# XGBoost Model\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')  # Initialize the XGBClassifier\n",
    "xgb.fit(X_train, y_train_encoded)  # Fit the model\n",
    "\n",
    "# Predicting\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "# Accuracy of Prediction\n",
    "print('Accuracy of XGBoost classifier on training set: {}'.format(xgb.score(X_train, y_train_encoded)))\n",
    "print('Accuracy of XGBoost classifier on test set: {}'.format(xgb.score(X_test, y_test_encoded)))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_df = confusion_matrix(y_test_encoded, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_df)\n",
    "\n",
    "# Classification Report\n",
    "metric_report = classification_report(y_test_encoded, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(metric_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c47ca6-4c82-474b-af1f-b40a443eb08d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61178dd4-6d9e-499e-8170-a11084cced62",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dad3b127-c98c-4101-a0ef-95cb05a28f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41, 4) (18, 4) (41,) (18,)\n",
      "Accuracy of Random Forest classifier on training set: 1.0\n",
      "Accuracy of Random Forest classifier on test set: 0.8888888888888888\n",
      "[[5 0 0 1]\n",
      " [0 1 0 0]\n",
      " [0 0 5 1]\n",
      " [0 0 0 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.83      0.91         6\n",
      "           2       1.00      1.00      1.00         1\n",
      "           3       1.00      0.83      0.91         6\n",
      "           4       0.71      1.00      0.83         5\n",
      "\n",
      "    accuracy                           0.89        18\n",
      "   macro avg       0.93      0.92      0.91        18\n",
      "weighted avg       0.92      0.89      0.89        18\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_table('D:\\\\5.1_Machine_Learning_Code\\\\Classification\\\\fruit_data_with_colors.txt')\n",
    "df.head()\n",
    "\n",
    "# Input and Output Variables\n",
    "feature_names = ['mass', 'width', 'height', 'color_score']\n",
    "X = df[feature_names]\n",
    "y = df['fruit_label']\n",
    "\n",
    "# Scaling X\n",
    "scaler = MinMaxScaler()\n",
    "scaled_X = scaler.fit_transform(X)\n",
    "\n",
    "# Splitting dataset into Train and Test (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.30, random_state=1, stratify=y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# Random Forest Classifier Model\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predicting\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Accuracy of Prediction\n",
    "print('Accuracy of Random Forest classifier on training set: {}'.format(rf.score(X_train, y_train)))\n",
    "print('Accuracy of Random Forest classifier on test set: {}'.format(rf.score(X_test, y_test)))\n",
    "\n",
    "# Combine y_test and y_pred into a DataFrame for evaluation\n",
    "test_calc = pd.concat([pd.DataFrame(y_test).reset_index(drop=True), pd.DataFrame(y_pred).reset_index(drop=True)], axis=1)\n",
    "test_calc.rename(columns={0: 'predicted'}, inplace=True)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_df = confusion_matrix(test_calc['fruit_label'], test_calc['predicted'])\n",
    "print(conf_df)\n",
    "\n",
    "# Classification Report\n",
    "metric_report = classification_report(test_calc['fruit_label'], test_calc['predicted'])\n",
    "print(metric_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26332002-63df-44d4-850d-91fdc276b3df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9ef4348-0ca3-4267-80e8-c174dbe9e873",
   "metadata": {},
   "source": [
    "#How to consider over fitting and under fitting? what are the margins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02365c21-4412-4c6c-b044-d62ca08fc4dd",
   "metadata": {},
   "source": [
    "#Reagrding Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7681ce6c-baf4-4bef-b02d-b25fa0eeeb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b9246-d2e4-44a9-8e0c-2a54683da7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbf5e4f-c8a3-42cb-8e32-2f4b9044b2e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
